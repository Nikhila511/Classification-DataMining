{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mis error:  0.029296875\n",
      "alpha:  1.7502699124972094\n",
      "mis error:  0.025150905432595502\n",
      "alpha:  1.8286943935112843\n",
      "mis error:  0.01702786377708955\n",
      "alpha:  2.0278648630471676\n",
      "mis error:  0.015685039370078573\n",
      "alpha:  2.0696192880459963\n",
      "mis error:  0.016766926916677236\n",
      "alpha:  2.0357189428523523\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "********\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "fold:  1\n",
      "Accuracy:  0.9649122807017544  Precision:  0.9473684210526315  recall:  0.9473684210526315  f1_measure:  0.9473684210526315\n",
      "mis error:  0.021484375\n",
      "alpha:  1.9093554141432472\n",
      "mis error:  0.02894211576846324\n",
      "alpha:  1.7565441260997625\n",
      "mis error:  0.012332990750257025\n",
      "alpha:  2.1915338795911423\n",
      "mis error:  0.005463059313215422\n",
      "alpha:  2.602134147986493\n",
      "mis error:  0.0005231493591420392\n",
      "alpha:  3.7775601334434734\n",
      "[0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
      "********\n",
      "[0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 1.]\n",
      "fold:  2\n",
      "Accuracy:  0.9298245614035088  Precision:  0.9565217391304348  recall:  0.88  f1_measure:  0.9166666666666666\n",
      "mis error:  0.0390625\n",
      "alpha:  1.6013732214691585\n",
      "mis error:  0.03861788617886148\n",
      "alpha:  1.6073282046627504\n",
      "mis error:  0.01215644820295989\n",
      "alpha:  2.198832295763204\n",
      "mis error:  0.016746923488496622\n",
      "alpha:  2.0363259855776326\n",
      "mis error:  0.02025415064024568\n",
      "alpha:  1.9394667291025451\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "********\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "fold:  3\n",
      "Accuracy:  0.9649122807017544  Precision:  0.9411764705882353  recall:  0.9411764705882353  f1_measure:  0.9411764705882353\n",
      "mis error:  0.01953125\n",
      "alpha:  1.9580075133488417\n",
      "mis error:  0.026892430278884178\n",
      "alpha:  1.7943248930192321\n",
      "mis error:  0.011770726714432004\n",
      "alpha:  2.2151495332496793\n",
      "mis error:  0.010616261004660845\n",
      "alpha:  2.267347690371294\n",
      "mis error:  0.01287427181172264\n",
      "alpha:  2.1697832644329718\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "********\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      "fold:  4\n",
      "Accuracy:  0.9298245614035088  Precision:  0.9  recall:  0.9  f1_measure:  0.9\n",
      "mis error:  0.03125\n",
      "alpha:  1.7169936022425731\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import operator\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(suppress=True) #prevent numpy exponential\n",
    "\n",
    "class Tree_node(object):\n",
    "    \n",
    "    question_val = None\n",
    "    true_child = None\n",
    "    false_child = None\n",
    "    feature_ind = None\n",
    "    label = None\n",
    "    \n",
    "    def __init__(self, question_val, true_child, false_child, feature_ind, label):\n",
    "        self.question_val = question_val\n",
    "        self.true_child = true_child\n",
    "        self.false_child = false_child\n",
    "        self.feature_ind = feature_ind\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def read_data(file):\n",
    "    nominal = dict()\n",
    "    gene_data = open(file)\n",
    "    gene_seq = gene_data.readlines()\n",
    "    all_genes_list = []\n",
    "    first_row = gene_seq[0].split(\"\\t\")\n",
    "    for f in range(len(first_row)):\n",
    "        try:\n",
    "            float(first_row[f])\n",
    "        except:\n",
    "            nominal[f] = []\n",
    "    for line in gene_seq:\n",
    "        gene = line.strip().split(\"\\t\")\n",
    "        for f in range(len(gene)):\n",
    "            try:\n",
    "                gene[f] = float(gene[f])\n",
    "            except:\n",
    "                category = nominal[f]\n",
    "                if gene[f] in category:\n",
    "                    gene[f] = float(category.index(gene[f]))\n",
    "                else:\n",
    "                    category.append(gene[f])\n",
    "                    gene[f] = float(category.index(gene[f]))\n",
    "        all_genes_list.append(gene)\n",
    "    return nominal, np.asarray(all_genes_list, dtype = float)\n",
    "\n",
    "def compute_giniIndex(feature_col, train_classes, split_val,is_nominal):\n",
    "    true_dict = dict()\n",
    "    true_cnt = 0\n",
    "    false_dict = dict()\n",
    "    false_cnt = 0\n",
    "    for row in range(len(feature_col)):\n",
    "        \n",
    "        if((is_nominal and (feature_col[row] == split_val)) or (not(is_nominal) and (feature_col[row] < split_val))):\n",
    "            # increment true dict count for corresponding class\n",
    "            if train_classes[row] in true_dict:\n",
    "                true_dict[train_classes[row]] += 1\n",
    "            else:\n",
    "                true_dict[train_classes[row]] = 1\n",
    "            true_cnt +=1\n",
    "        else:\n",
    "            # increment false dict count for corresponding class\n",
    "            if train_classes[row] in false_dict:\n",
    "                false_dict[train_classes[row]] += 1\n",
    "            else:\n",
    "                false_dict[train_classes[row]] = 1\n",
    "            false_cnt += 1\n",
    "                \n",
    "    if(len(true_dict) == 0):\n",
    "        true_gini = 1.0\n",
    "    else:\n",
    "        proportion = 0.0\n",
    "        for c in true_dict:\n",
    "            p = (true_dict[c]/true_cnt)\n",
    "            proportion += p**2\n",
    "        true_gini = 1-proportion\n",
    "        \n",
    "    if(len(false_dict) == 0):\n",
    "        false_gini = 1.0\n",
    "    else:\n",
    "        proportion = 0.0\n",
    "        for c in false_dict:\n",
    "            p = (false_dict[c]/false_cnt)\n",
    "            proportion += p**2\n",
    "        false_gini = 1-proportion\n",
    "    # final gini from all groups\n",
    "    return ((true_cnt/len(train_classes))*true_gini) + ((false_cnt/len(train_classes))*false_gini)\n",
    "    \n",
    "\n",
    "def find_best_split(train_data,train_classes,nominal_dict):\n",
    "    final_gini = 1\n",
    "    final_question_val = None\n",
    "    final_feature_ind = 0\n",
    "    for f in range(len(train_data[0])):  #iterate features\n",
    "        is_nominal = False \n",
    "        computed_ginis = set()\n",
    "        local_gini = 1\n",
    "        local_ques = None\n",
    "        local_feature_ind = 0\n",
    "        if f in nominal_dict:\n",
    "            is_nominal = True\n",
    "        for r in range(len(train_data)):  # iterate every record for the feature\n",
    "            if train_data[r][f] in computed_ginis:\n",
    "                continue\n",
    "            gini = compute_giniIndex(train_data[:,f], train_classes, train_data[r][f],is_nominal)\n",
    "            if gini < local_gini:\n",
    "                local_gini = gini\n",
    "                local_ques = train_data[r][f]\n",
    "                local_feature_ind = f\n",
    "            computed_ginis.add(train_data[r][f])\n",
    "        \n",
    "        if local_gini < final_gini:\n",
    "                final_gini = local_gini\n",
    "                final_question_val = local_ques\n",
    "                final_feature_ind = local_feature_ind\n",
    "#     print(\"final gini: \",final_gini)\n",
    "#     print('ques: ',final_question_val)\n",
    "#     print(\"features_ind: \",final_feature_ind)\n",
    "    return final_question_val,final_feature_ind\n",
    "    \n",
    "def assign_majority_class(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    max_cnt = 0\n",
    "    majority_class = None\n",
    "    for c in unique_labels:\n",
    "        count = np.count_nonzero(labels == c)\n",
    "        if count > max_cnt:\n",
    "            max_cnt = count\n",
    "            majority_class = c\n",
    "    return majority_class\n",
    "    \n",
    "def compute_tree(train_data,train_classes,nominal_dict):\n",
    "    if(len(np.unique(train_classes)) <= 1):\n",
    "        return Tree_node(None,None,None,None,train_classes[0])\n",
    "    nominal = False\n",
    "    question_val, feature_ind = find_best_split(train_data,train_classes,nominal_dict)\n",
    "    if feature_ind in nominal_dict:\n",
    "        nominal = True\n",
    "    cur_node = Tree_node(question_val,None,None,feature_ind,None)\n",
    "    true_data = []\n",
    "    true_classes = []\n",
    "    false_data = []\n",
    "    false_classes = []\n",
    "    for row in range(len(train_data[:,feature_ind])):\n",
    "        if((nominal and (train_data[row][feature_ind] == question_val)) or (not(nominal) and (train_data[row][feature_ind] < question_val))):\n",
    "            #Populating left-->true side data\n",
    "            true_data.append(train_data[row])\n",
    "            true_classes.append(train_classes[row])\n",
    "        else:\n",
    "            #Populating right-->false side data\n",
    "            false_data.append(train_data[row])\n",
    "            false_classes.append(train_classes[row])\n",
    "\n",
    "    if len(true_data)==0:\n",
    "        return Tree_node(None,None,None,None,assign_majority_class(false_classes))\n",
    "    if len(false_data)==0:\n",
    "        return Tree_node(None,None,None,None,assign_majority_class(true_classes))\n",
    "    cur_node.true_child = compute_tree(np.asarray(true_data),true_classes,nominal_dict)\n",
    "    cur_node.false_child = compute_tree(np.asarray(false_data),false_classes,nominal_dict)\n",
    "    \n",
    "    return cur_node\n",
    "\n",
    "def get_class_from_tree(test_data, root, nominal_dict):\n",
    "    if root.label != None:\n",
    "        return root.label\n",
    "    col = root.feature_ind\n",
    "    val = root.question_val\n",
    "    nominal = False\n",
    "    if col in nominal_dict:\n",
    "        nominal = True\n",
    "    if((nominal and (test_data[col] == val)) or (not(nominal) and (test_data[col] < val))):\n",
    "        return get_class_from_tree(test_data, root.true_child, nominal_dict)\n",
    "    else:\n",
    "        return get_class_from_tree(test_data, root.false_child, nominal_dict)\n",
    "\n",
    "def predict_train_classes(test_data, root, nominal_dict):\n",
    "    predicted_classes = []\n",
    "    for i in range(len(test_data)):\n",
    "        test_class = get_class_from_tree(test_data[i], root, nominal_dict)\n",
    "        predicted_classes.append(test_class)\n",
    "    return predicted_classes\n",
    "\n",
    "def calculate_misclassification(predicted_classes, train_classes, weights):\n",
    "    error = 0\n",
    "    for i in range(len(predicted_classes)):\n",
    "        if predicted_classes[i] != train_classes[i]:\n",
    "            error += weights[i]\n",
    "    return error\n",
    "    \n",
    "def calculate_updated_weights(weights, predicted_classes, actual_classes, alpha):\n",
    "    sum = 0\n",
    "    for i in range(len(predicted_classes)):\n",
    "        if predicted_classes[i] != actual_classes[i]:\n",
    "            weights[i] *= np.math.exp(alpha)\n",
    "        else:\n",
    "            weights[i] *= np.math.exp(-1*alpha)\n",
    "        sum += weights[i]\n",
    "    for w in range(len(weights)):\n",
    "        weights[w] /= sum \n",
    "    return weights\n",
    "\n",
    "def find_predicted_classes(test_data, roots, alphas, nominal_dict):\n",
    "    class0_weight = 0\n",
    "    class1_weight = 0\n",
    "    predicted_classes = []\n",
    "    for t in range(len(test_data)):\n",
    "        class0_weight = 0\n",
    "        class1_weight = 0\n",
    "        for j in range(len(roots)):\n",
    "            predicted_class = get_class_from_tree(test_data[t], roots[j], nominal_dict)\n",
    "            if predicted_class == 0.0:\n",
    "                class0_weight += alphas[j]\n",
    "            else:\n",
    "                class1_weight += alphas[j]\n",
    "        if class0_weight >= class1_weight:\n",
    "            predicted_classes.append(0.0)\n",
    "        else:\n",
    "            predicted_classes.append(1.0)\n",
    "    return predicted_classes\n",
    "\n",
    "def calculate_metrics(predicted_classes, ground_truth):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for i in range(0, len(predicted_classes)):\n",
    "        if(predicted_classes[i] == 1 and ground_truth[i] == 1):\n",
    "            tp += 1\n",
    "        elif(predicted_classes[i] == 1 and ground_truth[i] == 0):\n",
    "            fp += 1\n",
    "        elif(predicted_classes[i] == 0 and ground_truth[i] == 1):\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    if (tp+fp) != 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if (tp+fn) != 0:\n",
    "        recall = tp / (tp + fn)   \n",
    "    else:\n",
    "        recall = 0\n",
    "    if ((2 * tp) + fp + fn) != 0:\n",
    "        f_1_measure = (2 * tp) / ((2 * tp) + fp + fn) \n",
    "    else:\n",
    "        f_1_measure = 0\n",
    "    return accuracy, precision, recall, f_1_measure\n",
    "\n",
    "nominal_dict, data = read_data(\"project3_dataset1.txt\")\n",
    "classes = data[:,len(data[0])-1]\n",
    "feature_data = data[:,:len(data[0])-1]\n",
    "kfold = KFold(10, True, 1)\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f_1_measure_list = []\n",
    "bag_count = 5\n",
    "count = 1\n",
    "for train, test in kfold.split(feature_data):\n",
    "    train_data = feature_data[train]\n",
    "    test_data = feature_data[test]\n",
    "    train_classes = classes[train]\n",
    "    test_classes = classes[test]\n",
    "    root_nodes = []\n",
    "    weights = []\n",
    "    alphas = []\n",
    "    for w in range(len(train)):\n",
    "        weights.append(1/len(train))\n",
    "        \n",
    "    for i in range(bag_count):\n",
    "       # misclassification_error = float(len(train))\n",
    "        misclassification_error = sys.maxsize\n",
    "        #print(\"weights: \", weights)\n",
    "        while (misclassification_error > 0.5):\n",
    "            sample_indices = np.random.choice(train, len(train), replace = True, p = weights)\n",
    "            sample_train_data = feature_data[sample_indices]\n",
    "            sample_train_classes = classes[sample_indices]\n",
    "            root_node = compute_tree(sample_train_data,sample_train_classes,nominal_dict) \n",
    "            predicted_classes = predict_train_classes(train_data, root_node, nominal_dict)\n",
    "            misclassification_error = calculate_misclassification(predicted_classes, train_classes, weights)\n",
    "            print(\"mis error: \",misclassification_error)\n",
    "        alpha = (1/2)*np.math.log((1-misclassification_error)/misclassification_error)\n",
    "        print(\"alpha: \", alpha)\n",
    "        alphas.append(alpha)\n",
    "        root_nodes.append(root_node)\n",
    "        weights = calculate_updated_weights(weights, predicted_classes, train_classes, alpha)\n",
    "    predicted_classes = find_predicted_classes(test_data, root_nodes, alphas, nominal_dict)\n",
    "    print(predicted_classes)\n",
    "    accuracy, precision, recall, f_1_measure = calculate_metrics(predicted_classes, test_classes)\n",
    "    print(\"fold: \", count)\n",
    "    count += 1\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f_1_measure_list.append(f_1_measure)\n",
    "    print(\"Accuracy: \", accuracy, \" Precision: \", precision, \" recall: \", recall, \" f1_measure: \", f_1_measure)\n",
    "print(\"Final Accuracy: \", mean(accuracy_list))\n",
    "print(\"Final Precision: \", mean(precision_list))\n",
    "print(\"Final Recall: \", mean(recall_list))\n",
    "print(\"Final F_1_measure: \", mean(f_1_measure_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
