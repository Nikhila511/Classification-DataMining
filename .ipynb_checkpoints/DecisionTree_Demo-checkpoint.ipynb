{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREES FOR DEMO DATA\n",
      "**************************\n",
      "Level order tree structure\n",
      "**************************\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-854b9d63d9ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Level order tree structure\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"**************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m \u001b[0mprint_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnominal_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-854b9d63d9ef>\u001b[0m in \u001b[0;36mprint_decision_tree\u001b[1;34m(root, nominal_dict)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Root Node split-criteria: {\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnominal_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestion_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 8"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import operator\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "from datetime import datetime\n",
    "import queue\n",
    "\n",
    "np.set_printoptions(suppress=True) #prevent numpy exponential\n",
    "\n",
    "class Tree_node(object):\n",
    "    \n",
    "    question_val = None\n",
    "    true_child = None\n",
    "    false_child = None\n",
    "    feature_ind = None\n",
    "    label = None\n",
    "    \n",
    "    def __init__(self, question_val, true_child, false_child, feature_ind, label):\n",
    "        self.question_val = question_val\n",
    "        self.true_child = true_child\n",
    "        self.false_child = false_child\n",
    "        self.feature_ind = feature_ind\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def read_data(file):\n",
    "    nominal = dict()\n",
    "    gene_data = open(file)\n",
    "    gene_seq = gene_data.readlines()\n",
    "    all_genes_list = []\n",
    "    first_row = gene_seq[0].split(\"\\t\")\n",
    "    for f in range(len(first_row)):\n",
    "        try:\n",
    "            float(first_row[f])\n",
    "        except:\n",
    "            nominal[f] = []\n",
    "    for line in gene_seq:\n",
    "        gene = line.strip().split(\"\\t\")\n",
    "        for f in range(len(gene)):\n",
    "            try:\n",
    "                gene[f] = float(gene[f])\n",
    "            except:\n",
    "                category = nominal[f]\n",
    "                if gene[f] in category:\n",
    "                    gene[f] = float(category.index(gene[f]))\n",
    "                else:\n",
    "                    category.append(gene[f])\n",
    "                    gene[f] = float(category.index(gene[f]))\n",
    "        all_genes_list.append(gene)\n",
    "    return nominal, np.asarray(all_genes_list, dtype = float)\n",
    "\n",
    "def compute_giniIndex(feature_col, train_classes, split_val,is_nominal):\n",
    "    true_dict = dict()\n",
    "    true_cnt = 0\n",
    "    false_dict = dict()\n",
    "    false_cnt = 0\n",
    "    for row in range(len(feature_col)):\n",
    "        \n",
    "        if((is_nominal and (feature_col[row] == split_val)) or (not(is_nominal) and (feature_col[row] < split_val))):\n",
    "            # increment true dict count for corresponding class\n",
    "            if train_classes[row] in true_dict:\n",
    "                true_dict[train_classes[row]] += 1\n",
    "            else:\n",
    "                true_dict[train_classes[row]] = 1\n",
    "            true_cnt +=1\n",
    "        else:\n",
    "            # increment false dict count for corresponding class\n",
    "            if train_classes[row] in false_dict:\n",
    "                false_dict[train_classes[row]] += 1\n",
    "            else:\n",
    "                false_dict[train_classes[row]] = 1\n",
    "            false_cnt += 1\n",
    "                \n",
    "    if(len(true_dict) == 0):\n",
    "        true_gini = 1.0\n",
    "    else:\n",
    "        proportion = 0.0\n",
    "        for c in true_dict:\n",
    "            p = (true_dict[c]/true_cnt)\n",
    "            proportion += p**2\n",
    "        true_gini = 1-proportion\n",
    "        \n",
    "    if(len(false_dict) == 0):\n",
    "        false_gini = 1.0\n",
    "    else:\n",
    "        proportion = 0.0\n",
    "        for c in false_dict:\n",
    "            p = (false_dict[c]/false_cnt)\n",
    "            proportion += p**2\n",
    "        false_gini = 1-proportion\n",
    "    # final gini from all groups\n",
    "    return ((true_cnt/len(train_classes))*true_gini) + ((false_cnt/len(train_classes))*false_gini)\n",
    "    \n",
    "\n",
    "def find_best_split(train_data,train_classes,nominal_dict):\n",
    "    final_gini = 1\n",
    "    final_question_val = None\n",
    "    final_feature_ind = 0\n",
    "    for f in range(len(train_data[0])):  #iterate features\n",
    "        is_nominal = False \n",
    "        computed_ginis = set()\n",
    "        local_gini = 1\n",
    "        local_ques = None\n",
    "        local_feature_ind = 0\n",
    "        if f in nominal_dict:\n",
    "            is_nominal = True\n",
    "        for r in range(len(train_data)):  # iterate every record for the feature\n",
    "            if train_data[r][f] in computed_ginis:\n",
    "                continue\n",
    "            gini = compute_giniIndex(train_data[:,f], train_classes, train_data[r][f],is_nominal)\n",
    "            if gini < local_gini:\n",
    "                local_gini = gini\n",
    "                local_ques = train_data[r][f]\n",
    "                local_feature_ind = f\n",
    "            computed_ginis.add(train_data[r][f])\n",
    "        \n",
    "        if local_gini < final_gini:\n",
    "                final_gini = local_gini\n",
    "                final_question_val = local_ques\n",
    "                final_feature_ind = local_feature_ind\n",
    "    return final_question_val,final_feature_ind\n",
    "    \n",
    "def assign_majority_class(labels):\n",
    "    print(\"in majority compute\")\n",
    "    unique_labels = np.unique(labels)\n",
    "    max_cnt = 0\n",
    "    majority_class = None\n",
    "    for c in unique_labels:\n",
    "        count = np.count_nonzero(labels == c)\n",
    "        if count > max_cnt:\n",
    "            max_cnt = count\n",
    "            majority_class = c\n",
    "    return majority_class\n",
    "    \n",
    "def compute_tree(train_data,train_classes,nominal_dict):\n",
    "    if(len(np.unique(train_classes)) <= 1):\n",
    "        return Tree_node(None,None,None,None,train_classes[0])\n",
    "    nominal = False\n",
    "    question_val, feature_ind = find_best_split(train_data,train_classes,nominal_dict)\n",
    "    if feature_ind in nominal_dict:\n",
    "        nominal = True\n",
    "    cur_node = Tree_node(question_val,None,None,feature_ind,None)\n",
    "    true_data = []\n",
    "    true_classes = []\n",
    "    false_data = []\n",
    "    false_classes = []\n",
    "    for row in range(len(train_data[:,feature_ind])):\n",
    "        if((nominal and (train_data[row][feature_ind] == question_val)) or (not(nominal) and (train_data[row][feature_ind] < question_val))):\n",
    "            #Populating left-->true side data\n",
    "            true_data.append(train_data[row])\n",
    "            true_classes.append(train_classes[row])\n",
    "        else:\n",
    "            #Populating right-->false side data\n",
    "            false_data.append(train_data[row])\n",
    "            false_classes.append(train_classes[row])\n",
    "\n",
    "    #Case when all the input rows are classied to one of the child nodes.\n",
    "    if len(true_data)==0:\n",
    "        return Tree_node(None,None,None,None,assign_majority_class(false_classes))\n",
    "    if len(false_data)==0:\n",
    "        return Tree_node(None,None,None,None,assign_majority_class(true_classes))\n",
    "    \n",
    "    cur_node.true_child = compute_tree(np.asarray(true_data),true_classes,nominal_dict)\n",
    "    cur_node.false_child = compute_tree(np.asarray(false_data),false_classes,nominal_dict)\n",
    "    \n",
    "    return cur_node\n",
    "\n",
    "def get_class_from_tree(test_data, root, nominal_dict):\n",
    "    if root.label != None:\n",
    "        return root.label\n",
    "    col = root.feature_ind\n",
    "    val = root.question_val\n",
    "    nominal = False\n",
    "    if col in nominal_dict:\n",
    "        nominal = True\n",
    "    if((nominal and (test_data[col] == val)) or (not(nominal) and (test_data[col] < val))):\n",
    "        return get_class_from_tree(test_data, root.true_child, nominal_dict)\n",
    "    else:\n",
    "        return get_class_from_tree(test_data, root.false_child, nominal_dict)\n",
    "\n",
    "def predict_test_classes(test_data, root, nominal_dict):\n",
    "    predicted_classes = []\n",
    "    for i in range(len(test_data)):\n",
    "        test_class = get_class_from_tree(test_data[i], root, nominal_dict)\n",
    "        predicted_classes.append(test_class)\n",
    "    return predicted_classes\n",
    "    \n",
    "def calculate_metrics(predicted_classes, ground_truth):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for i in range(0, len(predicted_classes)):\n",
    "        if(predicted_classes[i] == 1 and ground_truth[i] == 1):\n",
    "            tp += 1\n",
    "        elif(predicted_classes[i] == 1 and ground_truth[i] == 0):\n",
    "            fp += 1\n",
    "        elif(predicted_classes[i] == 0 and ground_truth[i] == 1):\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    if (tp+fp) != 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if (tp+fn) != 0:\n",
    "        recall = tp / (tp + fn) \n",
    "    else:\n",
    "        recall = 0\n",
    "    if ((2 * tp) + fp + fn) != 0:\n",
    "        f_1_measure = (2 * tp) / ((2 * tp) + fp + fn) \n",
    "    else:\n",
    "        f_1_measure = 0\n",
    "    return accuracy, precision, recall, f_1_measure\n",
    "\n",
    "def print_decision_tree(root,nominal_dict):\n",
    "    q = queue.Queue()\n",
    "    q.put(root)\n",
    "    if feature_ind in nominal_dict:\n",
    "        print(\"Root Node split-criteria: {\",int(root_node.feature_ind),\",\",nominal_dict[root_node.feature_ind][int(root_node.question_val)],\"}\")\n",
    "    else:\n",
    "        print(\"Root Node split-criteria: {\",int(root_node.feature_ind),\",\",root_node.question_val,\"}\")\n",
    "    while(not q.empty()):\n",
    "        r = q.get()\n",
    "        if(r.true_child != None):\n",
    "            if(r.true_child.label == None):\n",
    "                q.put(r.true_child)\n",
    "                if feature_ind in nominal_dict:\n",
    "                    print(\"Left Child: {\",int(r.true_child.feature_ind),\", \",nominal_dict[r.true_child.feature_ind][int(r.true_child.question_val)],\"}\")\n",
    "                else:\n",
    "                    print(\"Left Child: {\",int(r.true_child.feature_ind),\", \",r.true_child.question_val,\"}\")\n",
    "            else:\n",
    "                print(\"Left Leaf Node with label: \",int(r.true_child.label))\n",
    "        if(r.false_child != None):\n",
    "            if(r.false_child.label == None):\n",
    "                q.put(r.false_child)\n",
    "                if feature_ind in nominal_dict:\n",
    "                    print(\"Right Child: {\",int(r.false_child.feature_ind),\", \",nominal_dict[r.false_child.feature_ind][int(r.false_child.question_val)],\"}\")\n",
    "                else:\n",
    "                    print(\"Right Child: {\",int(r.false_child.feature_ind),\", \",r.false_child.question_val,\"}\")\n",
    "            else:\n",
    "                print(\"Right Leaf Node with label: \",int(r.false_child.label))\n",
    "print(\"DECISION TREES FOR DEMO DATA\")\n",
    "nominal_dict, data = read_data(\"project3_dataset2.txt\")\n",
    "classes = data[:,len(data[0])-1]\n",
    "feature_data = data[:,:len(data[0])-1]\n",
    "train_data = feature_data\n",
    "train_classes = classes\n",
    "root_node = compute_tree(train_data,train_classes,nominal_dict) \n",
    "print(\"**************************\")\n",
    "print(\"Level order tree structure\")\n",
    "print(\"**************************\")\n",
    "print_decision_tree(root_node,nominal_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
