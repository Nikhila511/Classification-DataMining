{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1\n",
      "Accuracy:  0.9649122807017544  Precision:  0.9473684210526315  recall:  0.9473684210526315  f1_measure:  0.9473684210526315\n",
      "fold:  2\n",
      "Accuracy:  0.9298245614035088  Precision:  0.9565217391304348  recall:  0.88  f1_measure:  0.9166666666666666\n",
      "fold:  3\n",
      "Accuracy:  1.0  Precision:  1.0  recall:  1.0  f1_measure:  1.0\n",
      "fold:  4\n",
      "Accuracy:  0.9298245614035088  Precision:  0.9  recall:  0.9  f1_measure:  0.9\n",
      "fold:  5\n",
      "Accuracy:  0.9122807017543859  Precision:  0.9545454545454546  recall:  0.84  f1_measure:  0.8936170212765957\n",
      "fold:  6\n",
      "Accuracy:  0.9649122807017544  Precision:  0.9047619047619048  recall:  1.0  f1_measure:  0.95\n",
      "fold:  7\n",
      "Accuracy:  0.9824561403508771  Precision:  0.9565217391304348  recall:  1.0  f1_measure:  0.9777777777777777\n",
      "fold:  8\n",
      "Accuracy:  0.8771929824561403  Precision:  0.9583333333333334  recall:  0.7931034482758621  f1_measure:  0.8679245283018868\n",
      "fold:  9\n",
      "Accuracy:  0.8947368421052632  Precision:  0.95  recall:  0.7916666666666666  f1_measure:  0.8636363636363636\n",
      "fold:  10\n",
      "Accuracy:  0.9107142857142857  Precision:  0.7333333333333333  recall:  0.9166666666666666  f1_measure:  0.8148148148148148\n",
      "Final Accuracy:  0.9366854636591478\n",
      "Final Precision:  0.9261385925287527\n",
      "Final Recall:  0.9068805202661827\n",
      "Final F_1_measure:  0.9131805593526737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import operator\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "\n",
    "np.set_printoptions(suppress=True) #prevent numpy exponential\n",
    "\n",
    "class Tree_node(object):\n",
    "    \n",
    "    question_val = None\n",
    "    true_child = None\n",
    "    false_child = None\n",
    "    feature_ind = None\n",
    "    label = None\n",
    "    \n",
    "    def __init__(self, question_val, true_child, false_child, feature_ind, label):\n",
    "        self.question_val = question_val\n",
    "        self.true_child = true_child\n",
    "        self.false_child = false_child\n",
    "        self.feature_ind = feature_ind\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def read_data(file):\n",
    "    nominal = dict()\n",
    "    gene_data = open(file)\n",
    "    gene_seq = gene_data.readlines()\n",
    "    all_genes_list = []\n",
    "    first_row = gene_seq[0].split(\"\\t\")\n",
    "    for f in range(len(first_row)):\n",
    "        try:\n",
    "            float(first_row[f])\n",
    "        except:\n",
    "            nominal[f] = []\n",
    "    for line in gene_seq:\n",
    "        gene = line.strip().split(\"\\t\")\n",
    "        for f in range(len(gene)):\n",
    "            try:\n",
    "                gene[f] = float(gene[f])\n",
    "            except:\n",
    "                category = nominal[f]\n",
    "                if gene[f] in category:\n",
    "                    gene[f] = float(category.index(gene[f]))\n",
    "                else:\n",
    "                    category.append(gene[f])\n",
    "                    gene[f] = float(category.index(gene[f]))\n",
    "        all_genes_list.append(gene)\n",
    "    return nominal, np.asarray(all_genes_list, dtype = float)\n",
    "\n",
    "def compute_giniIndex(feature_col, train_classes, split_val,is_nominal):\n",
    "    true_dict = dict()\n",
    "    true_cnt = 0\n",
    "    false_dict = dict()\n",
    "    false_cnt = 0\n",
    "    for row in range(len(feature_col)):\n",
    "        \n",
    "        if((is_nominal and (feature_col[row] == split_val)) or (not(is_nominal) and (feature_col[row] < split_val))):\n",
    "            # increment true dict count for corresponding class\n",
    "            if train_classes[row] in true_dict:\n",
    "                true_dict[train_classes[row]] += 1\n",
    "            else:\n",
    "                true_dict[train_classes[row]] = 1\n",
    "            true_cnt +=1\n",
    "        else:\n",
    "            # increment false dict count for corresponding class\n",
    "            if train_classes[row] in false_dict:\n",
    "                false_dict[train_classes[row]] += 1\n",
    "            else:\n",
    "                false_dict[train_classes[row]] = 1\n",
    "            false_cnt += 1\n",
    "                \n",
    "    if(len(true_dict) == 0):\n",
    "        true_gini = 1.0\n",
    "    else:\n",
    "        proportion = 0.0\n",
    "        for c in true_dict:\n",
    "            p = (true_dict[c]/true_cnt)\n",
    "            proportion += p**2\n",
    "        true_gini = 1-proportion\n",
    "        \n",
    "    if(len(false_dict) == 0):\n",
    "        false_gini = 1.0\n",
    "    else:\n",
    "        proportion = 0.0\n",
    "        for c in false_dict:\n",
    "            p = (false_dict[c]/false_cnt)\n",
    "            proportion += p**2\n",
    "        false_gini = 1-proportion\n",
    "    # final gini from all groups\n",
    "    return ((true_cnt/len(train_classes))*true_gini) + ((false_cnt/len(train_classes))*false_gini)\n",
    "    \n",
    "\n",
    "def find_best_split(train_data,train_classes,nominal_dict):\n",
    "    final_gini = 1\n",
    "    final_question_val = None\n",
    "    final_feature_ind = 0\n",
    "    for f in range(len(train_data[0])):  #iterate features\n",
    "        is_nominal = False \n",
    "        computed_ginis = set()\n",
    "        local_gini = 1\n",
    "        local_ques = None\n",
    "        local_feature_ind = 0\n",
    "        if f in nominal_dict:\n",
    "            is_nominal = True\n",
    "        for r in range(len(train_data)):  # iterate every record for the feature\n",
    "            if train_data[r][f] in computed_ginis:\n",
    "                continue\n",
    "            gini = compute_giniIndex(train_data[:,f], train_classes, train_data[r][f],is_nominal)\n",
    "            if gini < local_gini:\n",
    "                local_gini = gini\n",
    "                local_ques = train_data[r][f]\n",
    "                local_feature_ind = f\n",
    "            computed_ginis.add(train_data[r][f])\n",
    "        \n",
    "        if local_gini < final_gini:\n",
    "                final_gini = local_gini\n",
    "                final_question_val = local_ques\n",
    "                final_feature_ind = local_feature_ind\n",
    "#     print(\"final gini: \",final_gini)\n",
    "#     print('ques: ',final_question_val)\n",
    "#     print(\"features_ind: \",final_feature_ind)\n",
    "    return final_question_val,final_feature_ind\n",
    "    \n",
    "def assign_majority_class(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    max_cnt = 0\n",
    "    majority_class = None\n",
    "    for c in unique_labels:\n",
    "        count = np.count_nonzero(labels == c)\n",
    "        if count > max_cnt:\n",
    "            max_cnt = count\n",
    "            majority_class = c\n",
    "    return majority_class\n",
    "    \n",
    "def compute_tree(train_data,train_classes,nominal_dict):\n",
    "    if(len(np.unique(train_classes)) <= 1):\n",
    "        return Tree_node(None,None,None,None,train_classes[0])\n",
    "    nominal = False\n",
    "    question_val, feature_ind = find_best_split(train_data,train_classes,nominal_dict)\n",
    "    if feature_ind in nominal_dict:\n",
    "        nominal = True\n",
    "    cur_node = Tree_node(question_val,None,None,feature_ind,None)\n",
    "    true_data = []\n",
    "    true_classes = []\n",
    "    false_data = []\n",
    "    false_classes = []\n",
    "    for row in range(len(train_data[:,feature_ind])):\n",
    "        if((nominal and (train_data[row][feature_ind] == question_val)) or (not(nominal) and (train_data[row][feature_ind] < question_val))):\n",
    "            #Populating left-->true side data\n",
    "            true_data.append(train_data[row])\n",
    "            true_classes.append(train_classes[row])\n",
    "        else:\n",
    "            #Populating right-->false side data\n",
    "            false_data.append(train_data[row])\n",
    "            false_classes.append(train_classes[row])\n",
    "\n",
    "    if len(true_data)==0:\n",
    "        return Tree_node(None,None,None,None,assign_majority_class(false_classes))\n",
    "    if len(false_data)==0:\n",
    "        return Tree_node(None,None,None,None,assign_majority_class(true_classes))\n",
    "    cur_node.true_child = compute_tree(np.asarray(true_data),true_classes,nominal_dict)\n",
    "    cur_node.false_child = compute_tree(np.asarray(false_data),false_classes,nominal_dict)\n",
    "    \n",
    "    return cur_node\n",
    "\n",
    "def get_class_from_tree(test_data, root, nominal_dict):\n",
    "    if root.label != None:\n",
    "        return root.label\n",
    "    col = root.feature_ind\n",
    "    val = root.question_val\n",
    "    nominal = False\n",
    "    if col in nominal_dict:\n",
    "        nominal = True\n",
    "    if((nominal and (test_data[col] == val)) or (not(nominal) and (test_data[col] < val))):\n",
    "        return get_class_from_tree(test_data, root.true_child, nominal_dict)\n",
    "    else:\n",
    "        return get_class_from_tree(test_data, root.false_child, nominal_dict)\n",
    "\n",
    "def predict_test_classes(test_data, roots, nominal_dict):\n",
    "    predicted_classes = []\n",
    "    for i in range(len(test_data)):\n",
    "        classes = []\n",
    "        for j in range(len(roots)):\n",
    "            test_class = get_class_from_tree(test_data[i], roots[j], nominal_dict)\n",
    "            classes.append(test_class)\n",
    "        pred_class = assign_majority_class(classes)    \n",
    "        predicted_classes.append(pred_class)\n",
    "    return predicted_classes\n",
    "    \n",
    "def calculate_metrics(predicted_classes, ground_truth):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for i in range(0, len(predicted_classes)):\n",
    "        if(predicted_classes[i] == 1 and ground_truth[i] == 1):\n",
    "            tp += 1\n",
    "        elif(predicted_classes[i] == 1 and ground_truth[i] == 0):\n",
    "            fp += 1\n",
    "        elif(predicted_classes[i] == 0 and ground_truth[i] == 1):\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    if (tp+fp) != 0:\n",
    "        precision = tp / (tp + fp)   \n",
    "    if (tp+fn) != 0:\n",
    "        recall = tp / (tp + fn)   \n",
    "    if ((2 * tp) + fp + fn) != 0:\n",
    "        f_1_measure = (2 * tp) / ((2 * tp) + fp + fn)    \n",
    "    return accuracy, precision, recall, f_1_measure\n",
    "\n",
    "nominal_dict, data = read_data(\"project3_dataset1.txt\")\n",
    "classes = data[:,len(data[0])-1]\n",
    "feature_data = data[:,:len(data[0])-1]\n",
    "kfold = KFold(10, True, 1)\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f_1_measure_list = []\n",
    "tree_count = 5\n",
    "count = 1\n",
    "for train, test in kfold.split(feature_data):\n",
    "    #train_data = feature_data[train]\n",
    "    test_data = feature_data[test]\n",
    "    #train_classes = classes[train]\n",
    "    test_classes = classes[test]\n",
    "    root_nodes = []\n",
    "    for i in range(tree_count):\n",
    "        sample_indices = np.random.choice(train, len(train),replace=True)\n",
    "        sample_train_data = feature_data[sample_indices]\n",
    "        sample_train_classes = classes[sample_indices]\n",
    "        root_node = compute_tree(sample_train_data,sample_train_classes,nominal_dict) \n",
    "        root_nodes.append(root_node)\n",
    "    predicted_classes = predict_test_classes(test_data, root_nodes, nominal_dict)\n",
    "    #print(predicted_classes)\n",
    "    accuracy, precision, recall, f_1_measure = calculate_metrics(predicted_classes, test_classes)\n",
    "    print(\"fold: \", count)\n",
    "    count += 1\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f_1_measure_list.append(f_1_measure)\n",
    "    print(\"Accuracy: \", accuracy, \" Precision: \", precision, \" recall: \", recall, \" f1_measure: \", f_1_measure)\n",
    "print(\"Final Accuracy: \", mean(accuracy_list))\n",
    "print(\"Final Precision: \", mean(precision_list))\n",
    "print(\"Final Recall: \", mean(recall_list))\n",
    "print(\"Final F_1_measure: \", mean(f_1_measure_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
